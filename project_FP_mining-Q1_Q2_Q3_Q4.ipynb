{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h1><strong>CSCI 4455/5455&ndash; Fall 2021</strong></h1>\n",
    "\n",
    "<h2><strong>Assignment 3 - Frequent Pattern Mining</strong></h2>\n",
    "\n",
    "<h3><strong><span style=\"color:#cc3300;\">Due: November 19, 11:59pm </span></strong></h3>\n",
    "\n",
    "<h3><strong>Your name:</strong></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<ul>\n",
    "<li style=\"text-align: justify;\">Please note that you must do this assignment&nbsp;<span style=\"color: #cc3300;\"><strong><u>individually</u></strong></span>. Using automatic tools, your code will be checked against other submissions and other existing resources (such as websites and books).</li>\n",
    "<li style=\"text-align: justify;\">This assignment is more extensive and might take longer than previous assignments to finish. <span style=\"color: #339966;\"><strong><u>Please start early on.</u></strong></span></li>\n",
    "<li style=\"text-align: justify;\">Review the lecture notes before starting with this assignment. Then, thoroughly read this document before starting with the implementation or thinking about the solution.</li>\n",
    "<li style=\"text-align: justify;\">If you have technical questions about Python, please Google the error messages and share the error message alongside the solution that got it fixed on Microsoft Teams, as your classmates may run into the same issues.</li>\n",
    "<li style=\"text-align: justify;\">Check Canvas regularly for possible clarifications and updates.</li>\n",
    "<li style=\"text-align: justify;\">There are libraries and scripts for frequent pattern mining, but you are <span style=\"color: #cc3300;\"><strong>prohibited to use these existing resources</strong></span>, which means you <span style=\"color: #cc3300;\"><strong>cannot include public libraries</strong></span>, or <span style=\"color: #cc3300;\"><strong>modify existing programs</strong></span> since the purpose   of   this   programming   assignment   is   to   help you understand and implement frequent pattern mining algorithms. You need to develop your code from scratch.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><strong>Assignment Objectives</strong></h2>\n",
    "<li style=\"text-align: justify;\">1. To implement the <span style=\"color: #339966;\"><strong>FP-Growth</strong></span> algorithm and test it under different configurations</li>\n",
    "<li style=\"text-align: justify;\">2. To mine maximal patterns</li>\n",
    "<li style=\"text-align: justify;\">3. To mine association rules from the frequent patterns</li>\n",
    "<li style=\"text-align: justify;\">4. To perform a sensitivity analysis on the minimum support threshold</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Dataset</h2>\n",
    "\n",
    "<p style=\"text-align: justify;\">A dataset is provided with this assignment that contains retail market basket data from an anonymous Belgian retail store. \n",
    "    \n",
    "The retail dataset was originally used in the following paper: <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.3296&rep=rep1&type=pdf\">paper link.</a>\n",
    "\n",
    "    \n",
    "Each line in the .txt file shows the items purchased in one transaction (transaction IDs are not provided), and items are separated by a space.    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Implementation</h2>\n",
    "\n",
    "<p style=\"text-align: justify;\">Please consider the following in your implementation:<br>\n",
    "    \n",
    "<ul>\n",
    "\n",
    "<li style=\"text-align: justify;\">You are not allowed to use frequent itemset mining libraries and need to implement your code from scratch. However, you are allowed to use Python built-in functions, such as min, max, average, map, apply, reduce, etc.</li>\n",
    "<li style=\"text-align: justify;\">Ensure that the cells in your Notebook are ordered correctly so that the “run all” option can run all cells without running to dependency issues.</li>\n",
    "</ul>\n",
    "\n",
    "<span style=\"text-align: justify;\"><strong><u>Hint</u></strong> Running the code with the provided dataset may take a long time. Moreover, verifying the correctness of your code with the provided dataset is not easy since it contains many transactions. Therefore, you should use a small dataset with a few transactions during the implementation to test your code fast and verify the results. However, note that you may obtain correct results for a small dataset, even though your code may have bugs, so eventually, you should try your code with the larger dataset.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "from itertools import combinations\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_name =   'retail.txt'     # dataset_name: that is the dataset name (such as dataset.txt)\n",
    "patterns_path =  'patterns.csv'   # the file name that will store the frequent patterns\n",
    "rules_path =     'rules.csv'      # the file name that will store the maximal patterns\n",
    "maximal_path =   'maximal.csv'    # the file name that will store the association rules\n",
    "min_support =     0.0015            # minimuum support threshold which is in percentage format (for example 0.2 means 20%)\n",
    "min_confidence =  0.9             # the minimum confidence threshold in the percentage format\n",
    "\n",
    "datasetFile = open(\"project.dataset1.txt\", \"r\")\n",
    "listOfItems = []\n",
    "frequency = []\n",
    "for line in datasetFile:\n",
    "    strippedLine = line.strip()\n",
    "    lineList = strippedLine.split()\n",
    "    listOfItems.append(lineList)\n",
    "    frequency.append(1)\n",
    "\n",
    "datasetFile.close()\n",
    "\n",
    "numberOfTransaction = len(listOfItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that in the rest of this Notebook, support count refers to the raw frequency (i.e., the number of times an itemsets occurs in a database), while support is the normalized support count which is equal to $\\frac{\\text{support count}}{\\text{the number of transactions}}$ </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Implement the FP-Growth Algorithm (40 Points)</h2>\n",
    "\n",
    "<p style=\"text-align: justify;\">Implement the FP-Growth algorithm, as discussed in the lecture notes. Display the total execution time, the total number of generated candidates, and the total number of frequent patterns in the following format (the provided values are hypothetical):\n",
    "\n",
    "    Execution time: 20 seconds\n",
    "    Candidates: 20,021\n",
    "    Frequent itemsets: 10,123\n",
    "    \n",
    "Each line must contain one pattern, its support count, and support. For example, the pattern A-B-C with support count 4 and support 0.5 must be saved in one line as A-B-C,4,0.5 in the <i><u>patterns.csv</u></i> file.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie the code to populate the transactions tidlist and implement the FP-Growth algorithm here\n",
    "# you can insert more cells below, if needed\n",
    "class Node:\n",
    "    def __init__(self, itemName, frequency, parentNode):\n",
    "        self.itemName = itemName\n",
    "        self.count = frequency\n",
    "        self.parent = parentNode\n",
    "        self.children = {}\n",
    "        self.next = None\n",
    "\n",
    "    def increment(self, frequency):\n",
    "        self.count += frequency\n",
    "    def display(self, ind=1):\n",
    "        print('  ' * ind, self.itemName, ' ', self.count)\n",
    "        for child in list(self.children.values()):\n",
    "            child.display(ind + 1)\n",
    "\n",
    "\n",
    "def updateHeaderTable(item, targetNode, headerTable):\n",
    "    if (headerTable[item][1] == None):\n",
    "        headerTable[item][1] = targetNode\n",
    "    else:\n",
    "        currentNode = headerTable[item][1]\n",
    "        # Traverse to the last node then link it to the target\n",
    "        while currentNode.next != None:\n",
    "            currentNode = currentNode.next\n",
    "        currentNode.next = targetNode\n",
    "\n",
    "def updateTree(item, treeNode, headerTable, frequency):\n",
    "    if item in treeNode.children:\n",
    "        # If the item already exists, increment the count\n",
    "        treeNode.children[item].increment(frequency)\n",
    "    else:\n",
    "        # Create a new branch\n",
    "        newItemNode = Node(item, frequency, treeNode)\n",
    "        treeNode.children[item] = newItemNode\n",
    "        # Link the new branch to header table\n",
    "        updateHeaderTable(item, newItemNode, headerTable)\n",
    "\n",
    "    return treeNode.children[item]\n",
    "\n",
    "def constructTree(itemSetList, frequency, minSup):\n",
    "    headerTable = defaultdict(int)\n",
    "    # Counting frequency and create header table\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        for item in itemSet:\n",
    "            headerTable[item] += frequency[idx]\n",
    "\n",
    "    # Deleting items below minSup\n",
    "    headerTable = dict((item, sup) for item, sup in headerTable.items() if sup >= minSup)\n",
    "    if (len(headerTable) == 0):\n",
    "        return None, None\n",
    "\n",
    "    # HeaderTable column [Item: [frequency, headNode]]\n",
    "    for item in headerTable:\n",
    "        headerTable[item] = [headerTable[item], None]\n",
    "\n",
    "    # Init Null head node\n",
    "    fpTree = Node('Null', 1, None)\n",
    "    # Update FP tree for each cleaned and sorted itemSet\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        itemSet = [item for item in itemSet if item in headerTable]\n",
    "        itemSet.sort(key=lambda item: headerTable[item][0], reverse=True)\n",
    "        # Traverse from root to leaf, update tree with given item\n",
    "        currentNode = fpTree\n",
    "        for item in itemSet:\n",
    "            currentNode = updateTree(item, currentNode, headerTable, frequency[idx])\n",
    "\n",
    "    return fpTree, headerTable\n",
    "\n",
    "def ascendFPtree(node, prefixPath):\n",
    "    if node.parent != None:\n",
    "        prefixPath.append(node.itemName)\n",
    "        ascendFPtree(node.parent, prefixPath)\n",
    "\n",
    "\n",
    "def findPrefixPath(basePat, headerTable):\n",
    "    # First node in linked list\n",
    "    treeNode = headerTable[basePat][1]\n",
    "    condPats = []\n",
    "    frequency = []\n",
    "    while treeNode != None:\n",
    "        prefixPath = [basePat]\n",
    "        # From leaf node all the way to root\n",
    "        ascendFPtree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1:\n",
    "            # Storing the prefix path and it's corresponding count\n",
    "            condPats.append(prefixPath[1:])\n",
    "            frequency.append(treeNode.count)\n",
    "\n",
    "        # Go to next node\n",
    "        treeNode = treeNode.next\n",
    "    return condPats, frequency\n",
    "\n",
    "def reportPatters(headerTable):\n",
    "    df_patterns = pd.DataFrame(columns=['pattern','support_count','support'])\n",
    "    candidate = 0\n",
    "    sortedItemList = [item[0] for item in sorted(list(headerTable.items()), key=lambda p: p[1][0])]\n",
    "    for item in sortedItemList:\n",
    "        conditionalPattBase, frequency = findPrefixPath(item, headerTable)\n",
    "        for patt in conditionalPattBase:\n",
    "            candidate +=1\n",
    "            idx = conditionalPattBase.index(patt)\n",
    "            support_count = frequency[idx]\n",
    "            support = frequency[idx]/numberOfTransaction\n",
    "            if support >= min_support:\n",
    "                row = {'pattern':patt, \n",
    "                       'support_count':support_count, \n",
    "                       'support':support}\n",
    "                df_patterns = df_patterns.append(row,ignore_index=True)\n",
    "    df_patterns.pattern = df_patterns.pattern.astype(str)\n",
    "    df_patterns.pattern = df_patterns.pattern.str.replace(\"'\",\"\")\n",
    "    df_patterns.pattern = df_patterns.pattern.str.replace(\"[\",\"\",regex=True)\n",
    "    df_patterns.pattern = df_patterns.pattern.str.replace(\"]\",\"\",regex=True)\n",
    "    df_patterns.pattern = df_patterns.pattern.str.replace(\",\",\"-\",regex=True)\n",
    "    df_patterns.pattern = df_patterns.pattern.str.replace(\" \",\"\",regex=True)\n",
    "    frItemSet = df_patterns.shape[0]\n",
    "    df_patterns.to_csv(patterns_path,index=False) \n",
    "    return frItemSet,candidate\n",
    "  \n",
    "startTime = time.time()\n",
    "fpTree, headerTable = constructTree(listOfItems,frequency,min_support)\n",
    "frItemSet, candidate = reportPatters(headerTable)\n",
    "endTime = time.time()\n",
    "print('Execution Time:',endTime - startTime)\n",
    "print('Candidate:',candidate)\n",
    "print('Frequent itemset:',frItemSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Find Maximal Itemsets (20 Points)</h2>\n",
    "\n",
    "<p style=\"text-align: justify;\">Find the maximal itemset among all the generated frequent patterns. You do not need to implement a maximal itemset mining algorithm (such as the Charm algorithm that allows for mining maximal itemsets without mining the frequent itemsets). Instead, you can simply iterate through the frequent itemsets and identify the maximal ones.\n",
    "\n",
    "<p style=\"text-align: justify;\">Finally, display the number of maximal patterns and the compression ratio in the following format (the provided values are hypothetical):\n",
    "\n",
    "    Frequent itemsets: 10,000\n",
    "    Maximal patterns: 1,500\n",
    "    Compression ratio: 85%\n",
    "\n",
    "As before, each line in your <i>maximal.csv</i> output file must contain one pattern, its support count, and support.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify;\"><strong>Hint</strong>: Iterate through the frequent itemsets with the reverse order that were mined in the previous step, i.e., from the longest itemset(s) to shorter one(s). </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie the code to implement and find maximal itemsets here\n",
    "# you can insert more cells below, if needed\n",
    "df_patterns = pd.read_csv(patterns_path)\n",
    "df_maximal = pd.DataFrame(columns=['pattern','support_count','support'])\n",
    "for index in df_patterns.index:\n",
    "    if(df_patterns.pattern.apply(lambda y : df_patterns.pattern.apply(lambda x : set(x).issubset(y)))[index].sum() == 1):\n",
    "        df_maximal = df_maximal.append([df_patterns.loc[index]],ignore_index=True)\n",
    "print('Frequent itemsets:',df_patterns.shape[0])\n",
    "print('Maximal patterns:',df_maximal.shape[0])\n",
    "print('Compression Ratio:'+\"{:.2%}\".format(1-df_maximal.shape[0]/df_patterns.shape[0]))\n",
    "df_maximal.to_csv(maximal_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Mine the Association Rules (30 Points)</h2>\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify;\">Implement association rule mining to generate strong association rules from the frequent itemsets generated in Step 1 using the below algorithm. Display the confidence for the top 20 rules with the highest confidence. Moreover, report the execution time as well as the number of strong rules in the following format (the provided values are hypothetical): </p>\n",
    "    \n",
    "    Execution time: 12 secodns \n",
    "    Strong rules: 2,300\n",
    "    Rule 1: A=>B,C, conf = 0.43\n",
    "    Rule 2: X=>Y, conf = 0.40\n",
    "\n",
    "Each line in the <i>rules.csv</i> file must contain one rule alongside its support count, support, and confidence. For example, A-B=>C,4,0.5,0.2 shows the support count, support, and confidence for the rule A-B=>C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie the code to implement and mine the association rules here\n",
    "# you can insert more cells below, if needed\n",
    "def find_rules(pattern_str):\n",
    "    subset = []\n",
    "    if len(pattern_str)<= 1:\n",
    "        return None\n",
    "    for i in range(1,len(pattern_str)):\n",
    "        for l in set(combinations(pattern_str,i)):\n",
    "            subset.append(''.join(l))\n",
    "        pattern_dic = {}\n",
    "        for pa in subset:\n",
    "            pattern_dic[pa]=set(pattern_str).difference(set(pa))\n",
    "    return pattern_dic\n",
    "\n",
    "def store_rules():\n",
    "    df_rules = pd.DataFrame(columns=['rules','support_count',\n",
    "                                     'support','confidence'])\n",
    "    support = lambda y : df_patterns.pattern.apply(lambda x : set(y).issubset(x)).sum()\n",
    "    for idx in df_patterns.index:\n",
    "        pattern_dic = find_rules(df_patterns.pattern[idx].replace('-',''))\n",
    "        if pattern_dic != None:\n",
    "            for key in pattern_dic.keys():\n",
    "                left_side_support = support(key)\n",
    "                confidence = df_patterns.support_count[idx]/left_side_support\n",
    "                patt = str(key)+'->'+str(pattern_dic[key]).replace('{','').replace('}','').replace(\"'\",'')\n",
    "                row = {'rules':patt, \n",
    "                       'support_count':df_patterns.support_count[idx],\n",
    "                       'support': df_patterns.support[idx],\n",
    "                       'confidence':confidence}\n",
    "                if confidence > min_confidence:\n",
    "                    df_rules = df_rules.append(row,ignore_index=True)\n",
    "    df_rules.to_csv(rules_path,index=False)\n",
    "    return df_rules.shape[0]\n",
    "        \n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "number_strong_rule = store_rules()\n",
    "df_rules = pd.read_csv(rules_path)\n",
    "df_rules.sort_values('confidence',inplace=True,ascending=False)\n",
    "print(df_rules.head(20))\n",
    "endTime = time.time()\n",
    "print('Number of Strong Rules:',number_strong_rule)\n",
    "print('Execution Time:',endTime - startTime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Sensitivity Analysis (10 Points)</h2>\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify;\">Run the frequent pattern mining function with the following values of minimum support and measure the total number of frequent patterns and generated candidates and the execution time. Next, draw three line plots using the matplotlib library that shows how minimum support (the x-axis) affects the runtime and the number of candidates and frequent itemsets (the y-axis). Note that x and y axes must have proper titles.\n",
    "    \n",
    "Minimum support values:\n",
    "    \n",
    "    0.0005, 0.001, 0.0015, 0.002, 0.0025, 0.003, 0.0035, 0.004, 0.0045, 0.005, 0.0055, 0.006, 0.0065, 0.007, 0.0075, 0.008, 0.0085, 0.009, 0.0095, 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie the code here\n",
    "# you can insert more cells below, if needed\n",
    "minimum_support_values = [0.0005, 0.001, 0.0015, 0.002, 0.0025, 0.003,\n",
    "                          0.0035, 0.004, 0.0045, 0.005, 0.0055, 0.006, \n",
    "                          0.0065, 0.007, 0.0075, 0.008, 0.0085, 0.009, \n",
    "                          0.0095, 0.01]\n",
    "\n",
    "def display_plot():\n",
    "    total_number_of_frequent_patterns = []\n",
    "    generated_candidates = []\n",
    "    execution_time = []\n",
    "    for min_support in minimum_support_values:\n",
    "        startTime = time.time()\n",
    "        fpTree, headerTable = constructTree(listOfItems,frequency,min_support)\n",
    "        frItemSet, candidate = reportPatters(headerTable)\n",
    "        endTime = time.time()\n",
    "        total_number_of_frequent_patterns.append(frItemSet)\n",
    "        generated_candidates.append(candidate)\n",
    "        execution_time.append(endTime-startTime)\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.plot(minimum_support_values,total_number_of_frequent_patterns, label='Total Number of Frequent Patterns') \n",
    "    ax.plot(minimum_support_values,generated_candidates, label='Generated Candidate') \n",
    "    ax.plot(minimum_support_values,execution_time, label='Execution Time')  # ... and some more.\n",
    "    ax.set_xlabel('Minimum Support Value')\n",
    "    ax.set_title(\"Sensitivity Analysis\")  \n",
    "    ax.legend()  \n",
    "\n",
    "display_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h3>Coding Considerations</h3>\n",
    "<p style=\"text-align: justify;\">You must consider the following in your implementations:</p>\n",
    "<ul>\n",
    "<li class=\"a\"><span> The output CSV files should be generated in the same directory of your code when you run it. Use the naming provided in the Implementation section. </span>\n",
    "<li class=\"a\"><span> You should write your code in this Jupyter Notebook (*.ipynb) file which can generate the required reports itself.</span>\n",
    "<li class=\"a\"><span> Your code should be self-explanatory. Make sure you add comments and your output files are formatted correctly. You might lose up to 30 points for bad code quality (readability, modularity, comments, efficiency, etc.) and formatting of the output files.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<h2>Submission</h2>\n",
    "<p style=\"text-align: justify;\">Your python file or Jupyter Notebook file must generate all the abovementioned reports when you run it.</p>\n",
    "<p style=\"text-align: justify;\">You need to submit a zip file in Canvas, including the following items: \n",
    "\n",
    "<ul>\n",
    "<li class=\"a\"><span> a Jupyter Notebook (*.ipynb) file, named assignment3.ipynb that contains your completed code </span>\n",
    "<li class=\"a\"><span> patterns.csv that contains the frequent patterns</span>\n",
    "<li class=\"a\"><span> maximal.csv that contains the maximal patterns</span>\n",
    "<li class=\"a\"><span> rules.csv that contains the association rules</span>\n",
    "<li class=\"a\"><span> results.pdf: a pdf file that contains all the requested charts and outputs (only copy the outputs (not the code itself) from your Notebook to this file. Also do not include the patterns and their supports in this file.)</span>\n",
    "    \n",
    "</li>\n",
    "</ul>\n",
    "    \n",
    "<span style=\"background-color: #ffff99;\">The file name should be in <strong>FirstName_LastName</strong> format</span>.</p>\n",
    "<p style=\"text-align: justify;\"><span style=\"background-color: #ffff99;\">DO NOT INCLUDE EXTRA FILES, SUCH AS THE INPUT DATASETS</span>, in your submission;</p>\n",
    "<p style=\"text-align: justify;\">Please download your assignment after submission and make sure it is not corrupted or empty! We will not be responsible for corrupted submissions and will not take a resubmission after the deadline.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h2>Need Help?</h2>\n",
    "<p>If you need help with this assignment, please get in touch with Erfan (on MS Teams or via email at <a href=\"mailto:erfan.jafarikhademzavareh@ucdenver.edu\">Erfan.jafarikhademzavareh@ucdenver.edu</a>) or go to his office hours.</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>You are highly encouraged to ask your question on the designated channel for Assignment 2 on Microsoft Teams (not necessarily monitored by the instructor/TA). Feel free to help other students with general questions. However, DO NOT share your solution.</p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
